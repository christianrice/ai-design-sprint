{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OPENAI_API_KEY from .env file\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = os.getenv('OPENAI_ORGANIZATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate list of experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "class Expert(BaseModel):\n",
    "    name: str = Field(description=\"Name of the expert\")\n",
    "    description: str = Field(description=\"Description of the expert in 20 words or less\")\n",
    "\n",
    "class Experts(BaseModel):\n",
    "    experts: List[Expert] = Field(description=\"List of experts\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Experts)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a member of a Design Sprint who is tasked with finding a panel of experts on the following design sprint goal: \n",
    "\n",
    "```\n",
    "{sprint_goal}\n",
    "```\n",
    "\n",
    "Define {num_experts} different dream personas of experts who could help with this scenario.\n",
    "\n",
    "For example, if the sprint problem were \"Bring great coffee to new customers online\" you would provide 5 personas similar to:\n",
    "\n",
    "```\n",
    "Steve\n",
    "Casual coffee drinker who sometimes goes to Starbucks but usually makes Folgers at home.\n",
    "\n",
    "Brian\n",
    "Coffee snob who roasts coffee at home, hand grinds it, and perfectly measures to the gram his morning cup of coffee.\n",
    "```\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Respond with NOTHING else but the valid JSON described above. Do not return a list. Do not return any preamble. Just return the JSON and nothing else at all.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"field_of_expertise\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "model = Ollama(model=\"mistral\")\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "sprint_goal = \"Create a service that helps adults handle the problems of their aging parents\"\n",
    "\n",
    "experts = chain.invoke({\"sprint_goal\": sprint_goal, \"num_experts\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expert in experts.experts:\n",
    "    print(expert.name + \": \" + expert.description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
